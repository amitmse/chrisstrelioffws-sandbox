<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="Christopher Strelioff's blog">
        <meta name="viewport" content="width=device-width">
        <title>Getting started with Latent Dirichlet Allocation in Python &mdash; chris&#39; sandbox</title>
            <link rel="stylesheet" href="../../../_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/main.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/flat.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="../../../_static/font-awesome.min.css" type="text/css">
        <link rel="stylesheet" href="../../../_static/jsdemo.css" type="text/css" /><link rel="stylesheet" href="../../../_static/style.css" type="text/css" /><link rel="shortcut icon" href="../../../_static/tinkerer.ico" /><!-- Load modernizr and JQuery -->
        <script src="../../../_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="../../../_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="../../../_static/plugins.js"></script>
        <script src="../../../_static/main.js"></script>
        <link rel="next" title="Inferring probabilities, a second example of Bayesian calculations" href="../../10/24/inferring_probabilities_a_second_example_of_bayesian_calculations.html" /><link rel="prev" title="Installing essentia for audio feature extraction" href="../../12/10/installing_essentia_for_audio_feature_extraction.html" /><link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '1.5',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="../../../_static/underscore.js"></script><script type="text/javascript" src="../../../_static/doctools.js"></script><script type="text/javascript" src="../../../_static/jsdemo.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="../../../_static/disqus.js"></script><script type="text/javascript" src="../../../_static/google_analytics.js"></script><script type="text/javascript" src="../../../_static/d3.min.js"></script>

    <script type="text/javascript">
        $(document).ready(function () {
            // Scroll to content if on small screen
            if (screen.width < 480)
            {
                $(document).scrollTop(document.getElementsByTagName("article")[0].offsetTop - 44);
            }
        });
    </script></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><header role="banner">
    <hgroup>
      <h1><a href="../../../index.html">chris&#39; sandbox</a></h1><h2>python, R, ubuntu, bayesian methods, machine learning and more...</h2></hgroup>
  </header>
<div class="main-container" role="main"><div class="main wrapper body clearfix"><article><div class="timestamp postmeta">
            <span>November 13, 2014</span>
        </div>
    <div class="section" id="getting-started-with-latent-dirichlet-allocation-in-python">
<h1>Getting started with Latent Dirichlet Allocation in Python</h1>
<p>In this post I will go over installation and basic usage of the <a class="reference external" href="https://github.com/ariddell/lda">lda</a> Python
package for Latent Dirichlet Allocation (LDA).  I <em>will not</em> go through the
theoretical foundations of the method in this post. However, the main reference
for this model, <a class="reference external" href="http://jmlr.org/papers/v3/blei03a.html">Blei etal 2003</a> is freely available online and I think
the main idea of assigning documents in a corpus (set of documents) to latent
(hidden) topics based on a vector of words is fairly simple to understand and
the example (from <a class="reference external" href="https://github.com/ariddell/lda">lda</a>) will help to solidify our understanding of the LDA
model. So, let&#8217;s get started...</p>
<div id="more"> </div><div class="section" id="installing-lda">
<h2>Installing lda</h2>
<p>In previous posts I have covered installing Python packages using <strong>pip</strong> and
<strong>virtualenwrapper</strong>, see the posts for more detailed information:</p>
<ul class="simple">
<li><a class="reference internal" href="../../06/04/install_and_setup_python_and_packages_on_ubuntu_14_04.html#initial-python-setup"><em>Install Python packages on Ubuntu 14.04</em></a></li>
<li><a class="reference internal" href="../../09/04/virtualenv_and_virtualenvwrapper_on_ubuntu_14_04.html#virtualenvs-on-ubuntu-14-04"><em>virtualenv and virtualenvwrapper on Ubuntu 14.04</em></a></li>
</ul>
<p>Briefly, there are two approaches I will mention:</p>
<ul class="simple">
<li><strong>Method 1</strong>:</li>
</ul>
<p>I will install <a class="reference external" href="https://github.com/ariddell/lda">lda</a> as a <em>user</em></p>
<div class="code bash highlight-python"><div class="highlight"><pre>$ pip install --user lda
</pre></div>
</div>
<p>This will also install the required <strong>pbr</strong> package.  Now I will have <a class="reference external" href="https://github.com/ariddell/lda">lda</a>
available in a setup with all the other packages I have previously installed
(again, see above).  With this method, you should get something like this after
install:</p>
<div class="code bash highlight-python"><div class="highlight"><pre>$ pip show lda
---
Name: lda
Version: 0.3.2
Location: /home/cstrelioff/.local/lib/python2.7/site-packages
Requires: pbr, numpy
</pre></div>
</div>
<p>I already had <strong>numpy</strong> installed, so it was not modified.</p>
<ul class="simple">
<li><strong>Method 2</strong>:</li>
</ul>
<p>If you want a completely isolated environment for <cite>lda</cite> you can use a
virtualenv (I&#8217;ll use virualenvwraper, as discussed in post listed above).
Please note that numpy will be downloaded and compiled if you choose this
approach. The install in this case would go something like this:</p>
<div class="code bash highlight-python"><div class="highlight"><pre>$ mkvirtualenv lda_env
New python executable in lda_env/bin/python
Installing setuptools, pip...done.
(lda_env)~$ pip install lda

..lots of numpy compilation...
</pre></div>
</div>
<p>In this case, <strong>pip</strong> will show the installation in the location specified for
your virtualenvs. For me, this looks like:</p>
<div class="code bash highlight-python"><div class="highlight"><pre>(lda_env)$ pip show lda
---
Name: lda
Version: 0.3.2
Location: /home/cstrelioff/virtenvs/lda_env/lib/python2.7/site-packages
Requires: pbr, numpy
</pre></div>
</div>
<p>Notice that the location is different than method 1.</p>
<p>So, that&#8217;s it, <a class="reference external" href="https://github.com/ariddell/lda">lda</a> is installed.  Let&#8217;s work through the example provided
along with the package.</p>
</div>
<div class="section" id="an-example">
<h2>An Example</h2>
<p>The example at the <a class="reference external" href="https://github.com/ariddell/lda">lda</a> github repository looks at corpus of Reuters news
releases&#8211; let&#8217;s replicate this and add some details to better understand what
is going on. A script containing all of the code to follow, called
<span class="code docutils literal"><span class="pre">ex002_lda.py</span></span>, is available at <a class="reference external" href="https://gist.github.com/cstrelioff/38b1d16a1253c962b7d7">this gist</a>.
To get started, we do some imports:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">lda</span>
<span class="kn">import</span> <span class="nn">lda.datasets</span>
</pre></div>
</div>
<p>Next, we import the data used for the example.  This is included with the
<a class="reference external" href="https://github.com/ariddell/lda">lda</a> package, so this step is simple (I also print out the data type and
size for each item):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># document-term matrix</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_reuters</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;type(X): {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;shape: {}</span><span class="se">\n</span><span class="s">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c"># the vocab</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_reuters_vocab</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;type(vocab): {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">vocab</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;len(vocab): {}</span><span class="se">\n</span><span class="s">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)))</span>

<span class="c"># titles for each story</span>
<span class="n">titles</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_reuters_titles</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;type(titles): {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">titles</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;len(titles): {}</span><span class="se">\n</span><span class="s">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">titles</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>type(X): &lt;type &#39;numpy.ndarray&#39;&gt;
shape: (395, 4258)

type(vocab): &lt;type &#39;tuple&#39;&gt;
len(vocab): 4258

type(titles): &lt;type &#39;tuple&#39;&gt;
len(titles): 395
</pre></div>
</div>
<p>From the above we can see that there are 395 news items (documents) and a
vocabulary of size 4258.  The document-term matrix, <span class="code docutils literal"><span class="pre">X</span></span>, has a count of
the number of occurences of each of the 4258 vocabulary words for each of the
395 documents.  For example, <span class="code docutils literal"><span class="pre">X[0,3117]</span></span> is the number of times that word
3117 occurs in document 0. We can find out the count and the word that this
corresponds to using (let&#8217;s also get the document title):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">doc_id</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">word_id</span> <span class="o">=</span> <span class="mi">3117</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;doc id: {} word id: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="n">word_id</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;-- count: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">doc_id</span><span class="p">,</span> <span class="n">word_id</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;-- word : {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">word_id</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;-- doc  : {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">doc_id</span><span class="p">]))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>doc id: 0 word id: 3117
-- count: 2
-- word : heir-to-the-throne
-- doc  : 0 UK: Prince Charles spearheads British royal revolution. LONDON
1996-08-20
</pre></div>
</div>
<p>Of course we should expect that there are lots of zeros in the <span class="code docutils literal"><span class="pre">X</span></span>
matrix&#8211; I chose this example to get a non-zero result.</p>
</div>
<div class="section" id="fiting-the-model">
<h2>Fiting the model</h2>
<p>Next we initialize and fit the LDA model.  To do this we have to choose the
number of topics (other methods can attempt to find the number of topics as
well, but for LDA we have to assume a number). Continuing with the
example we choose:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">LDA</span><span class="p">(</span><span class="n">n_topics</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>There are a couple of parameters for the prior that we leave at the default
values.  As far as I can tell, this only uses symmetric priors &#8211; I&#8217;ll have to
look into this more (see <a class="reference external" href="http://papers.nips.cc/paper/3854-rethinking-lda-why-priors-matter">Wallach etal 2009</a> for a discussion of this issue).</p>
</div>
<div class="section" id="topic-word">
<h2>Topic-Word</h2>
<p>From the fit model we can look at the topic-word probabilities:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">topic_word</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">topic_word_</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;type(topic_word): {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">topic_word</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;shape: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic_word</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>type(topic_word): &lt;type &#39;numpy.ndarray&#39;&gt;
shape: (20, 4258)
</pre></div>
</div>
<p>From the size of the output we can see that we have a distribution over the
4258 words in the vocabulary for each of the 20 topics. For each topic, the
probabilities of the words should be normalized. Let&#8217;s check the first 5:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">sum_pr</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">topic_word</span><span class="p">[</span><span class="n">n</span><span class="p">,:])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;topic: {} sum: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">sum_pr</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>topic: 0 sum: 1.0
topic: 1 sum: 1.0
topic: 2 sum: 1.0
topic: 3 sum: 1.0
topic: 4 sum: 1.0
</pre></div>
</div>
<p>We can also get the top 5 words for each topic (by probability):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">n</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">topic_dist</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">topic_word</span><span class="p">):</span>
    <span class="n">topic_words</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vocab</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">topic_dist</span><span class="p">)][:</span><span class="o">-</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&#39;*Topic {}</span><span class="se">\n</span><span class="s">- {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">topic_words</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>*Topic 0
- church people told years last
*Topic 1
- elvis music fans york show
*Topic 2
- pope trip mass vatican poland
*Topic 3
- film french against france festival
*Topic 4
- king michael romania president first
*Topic 5
- police family versace miami cunanan
*Topic 6
- germany german war political government
*Topic 7
- harriman u.s clinton churchill ambassador
*Topic 8
- yeltsin russian russia president kremlin
*Topic 9
- prince queen bowles church king
*Topic 10
- simpson million years south irish
*Topic 11
- charles diana parker camilla marriage
*Topic 12
- east peace prize president award
*Topic 13
- order nuns india successor election
*Topic 14
- pope vatican hospital surgery rome
*Topic 15
- mother teresa heart calcutta missionaries
*Topic 16
- bernardin cardinal cancer church life
*Topic 17
- died funeral church city death
*Topic 18
- museum kennedy cultural city culture
*Topic 19
- art exhibition century city tour
</pre></div>
</div>
<p>This gives us some sense of what the 20 topics might actually mean &#8211; can you
see the patterns?</p>
</div>
<div class="section" id="document-topic">
<h2>Document-Topic</h2>
<p>The other information we get from the model is document-topic probabilities:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">doc_topic</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">doc_topic_</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;type(doc_topic): {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">doc_topic</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;shape: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">doc_topic</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>type(doc_topic): &lt;type &#39;numpy.ndarray&#39;&gt;
shape: (395, 20)
</pre></div>
</div>
<p>Looking at the size of the output we can see that there is a distribution over
the 20 topics for each of the 395 documents.  These should be normalized for
each document, let&#8217;s test the first 5:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">sum_pr</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">doc_topic</span><span class="p">[</span><span class="n">n</span><span class="p">,:])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;document: {} sum: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">sum_pr</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>document: 0 sum: 1.0
document: 1 sum: 1.0
document: 2 sum: 1.0
document: 3 sum: 1.0
document: 4 sum: 1.0
</pre></div>
</div>
<p>Using the title of the new stories, we can sample the most probable topic:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">topic_most_pr</span> <span class="o">=</span> <span class="n">doc_topic</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;doc: {} topic: {}</span><span class="se">\n</span><span class="s">{}...&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">,</span>
                                            <span class="n">topic_most_pr</span><span class="p">,</span>
                                            <span class="n">titles</span><span class="p">[</span><span class="n">n</span><span class="p">][:</span><span class="mi">50</span><span class="p">]))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>doc: 0 topic: 11
0 UK: Prince Charles spearheads British royal revo...
doc: 1 topic: 0
1 GERMANY: Historic Dresden church rising from WW2...
doc: 2 topic: 15
2 INDIA: Mother Teresa&#39;s condition said still unst...
doc: 3 topic: 11
3 UK: Palace warns British weekly over Charles pic...
doc: 4 topic: 15
4 INDIA: Mother Teresa, slightly stronger, blesses...
doc: 5 topic: 15
5 INDIA: Mother Teresa&#39;s condition unchanged, thou...
doc: 6 topic: 15
6 INDIA: Mother Teresa shows signs of strength, bl...
doc: 7 topic: 15
7 INDIA: Mother Teresa&#39;s condition improves, many ...
doc: 8 topic: 15
8 INDIA: Mother Teresa improves, nuns pray for &quot;mi...
doc: 9 topic: 0
9 UK: Charles under fire over prospect of Queen Ca...
</pre></div>
</div>
<p>Looks pretty good except for topic 0&#8211; should docs 1 and 9 be given the same
topic? Doesn&#8217;t look like it.</p>
</div>
<div class="section" id="visualizing-the-inference">
<h2>Visualizing the inference</h2>
<p>Finally, let&#8217;s visualize some of the distributions.  To do that I&#8217;m going to
use matplotlib &#8211; you can see my previous posts (above) if you need help
installing.</p>
<p>First, we import matplotlib and set a style:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c"># use matplotlib style sheet</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s">&#39;ggplot&#39;</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="c"># version of matplotlib might not be recent</span>
    <span class="k">pass</span>
</pre></div>
</div>
<p>Next, let&#8217;s see what some of the topic-word distributions look like.  The idea
here is that each topic should have a distinct distribution of words. In the
stem plots below, the height of each stem reflects the probability of the word
in the focus topic:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">19</span><span class="p">]):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">topic_word</span><span class="p">[</span><span class="n">k</span><span class="p">,:],</span> <span class="n">linefmt</span><span class="o">=</span><span class="s">&#39;b-&#39;</span><span class="p">,</span>
               <span class="n">markerfmt</span><span class="o">=</span><span class="s">&#39;bo&#39;</span><span class="p">,</span> <span class="n">basefmt</span><span class="o">=</span><span class="s">&#39;w-&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">50</span><span class="p">,</span><span class="mi">4350</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">&quot;Prob&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;topic {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">&quot;word&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../../../_images/getting_started_with_latent_dirichlet_allocation_in_python_topic-work-plot_1.png"><img alt="../../../_images/getting_started_with_latent_dirichlet_allocation_in_python_topic-work-plot_1.png" src="../../../_images/getting_started_with_latent_dirichlet_allocation_in_python_topic-work-plot_1.png" style="width: 15cm;" /></a>
<p>Finally, let&#8217;s look at the topic distribution for a few documents.  These
distributions give the probability of each of the 20 topics for every
document.  I will only plot a few:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">doc_topic</span><span class="p">[</span><span class="n">k</span><span class="p">,:],</span> <span class="n">linefmt</span><span class="o">=</span><span class="s">&#39;r-&#39;</span><span class="p">,</span>
               <span class="n">markerfmt</span><span class="o">=</span><span class="s">&#39;ro&#39;</span><span class="p">,</span> <span class="n">basefmt</span><span class="o">=</span><span class="s">&#39;w-&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">&quot;Prob&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;Document {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">&quot;Topic&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../../../_images/getting_started_with_latent_dirichlet_allocation_in_python_doc_topic-plot_1.png"><img alt="../../../_images/getting_started_with_latent_dirichlet_allocation_in_python_doc_topic-plot_1.png" src="../../../_images/getting_started_with_latent_dirichlet_allocation_in_python_doc_topic-plot_1.png" style="width: 15cm;" /></a>
<p>Plotting the distribution of topics for the above documents provides an
important insight: many documents have more than one topic with high
probability.  As a result, choosing the topic with highest probability
for each document can be subject to uncertainty; <em>note to self: be careful</em>.
Maybe the full distribution over topics should be considered when comparing two
documents?</p>
<p>That&#8217;s it! As always, leave comments and questions below.</p>
</div>
</div>

    <div class="postmeta">
        <div class="author">
            <span>Posted by Chris Strelioff</span>
        </div>
        
        <div class="tags">
            <span>
                Tags:
                <a href="../../../tags/lda.html">LDA</a>, <a href="../../../tags/bayesian.html">Bayesian</a>, <a href="../../../tags/topic_models.html">topic models</a>, <a href="../../../tags/python.html">Python</a></span>
        </div>
        </div><ul class="related clearfix">
            <li class="left"> &laquo; <a href="../../12/10/installing_essentia_for_audio_feature_extraction.html">Installing essentia for audio feature extraction</a></li>
            <li class="right"><a href="../../10/24/inferring_probabilities_a_second_example_of_bayesian_calculations.html">Inferring probabilities, a second example of Bayesian calculations</a> &raquo; </li>
        </ul><div id="disqus_thread"></div><script type="text/javascript">    var disqus_shortname = "chrissandbox";    var disqus_identifier = "2014/11/13/getting_started_with_latent_dirichlet_allocation_in_python";    disqus_thread();</script><noscript>Please enable JavaScript to view the    <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></article><aside class="sidebar"><section><div class="widget" id="searchbox" role="search">
    <h1><a href="#searchbox">Search</a></h1>
    <form action="../../../search.html" method="get">
        <input type="text" name="q" />
        <button type="submit"><span class="fa fa-search"></span></button>
    </form>
</div></section><section><div class="widget">
  <h1>Pages</h1>
  <ul>
  <li>
      <a href="../../../index.html">Home</a>
    </li>
  </ul>
</div>
</section><section><div class="widget">
    <h1>Recent Posts</h1>
    <ul><li>
            <a href="../../../2015/05/27/revisiting_the_medical_tests_example_with_python_and_lea.html">Revisiting the medical tests example with Python and Lea</a>
        </li><li>
            <a href="../../../2015/05/04/probabilistic_programming_with_python_and_lea.html">Probabilistic programming with Python and Lea</a>
        </li><li>
            <a href="../../../2015/04/30/joins_and_some_views_in_mysql.html">JOINs, and some VIEWs, in MySQL</a>
        </li><li>
            <a href="../../../2015/04/22/employees_database_for_mysql_setup_and_simple_queries.html">Employees database for MySQL, setup and simple queries</a>
        </li><li>
            <a href="../../../2015/04/21/installing_mysql_on_ubuntu_14_04.html">Installing MySQL on Ubuntu 14.04</a>
        </li><li>
            <a href="../../../2015/04/03/getting_started_with_responsive_websites_and_javascript.html">Getting started with responsive websites and JavaScript</a>
        </li><li>
            <a href="../../../2015/03/03/installing_pysoundfile_on_ubuntu_14_04.html">Installing PySoundFile on Ubuntu 14.04</a>
        </li><li>
            <a href="../../../2015/02/17/install_qgis_on_ubuntu_14_04.html">Install QGIS on Ubuntu 14.04</a>
        </li><li>
            <a href="../../../2015/02/17/using_python_to_query_data_from_socrata.html">Using Python to query data from Socrata</a>
        </li><li>
            <a href="../../../2015/01/12/installing_node_js_and_npm_on_ubuntu_14_04.html">Installing Node.js and npm on Ubuntu 14.04</a>
        </li></ul>
</div>
</section><section><div class="widget">
    <h1>Tags</h1><a href="../../../tags/api.html">api</a> (1), <a href="../../../tags/audio.html">audio</a> (1), <a href="../../../tags/audio_features.html">audio features</a> (1), <a href="../../../tags/bayesian.html">Bayesian</a> (7), <a href="../../../tags/beta.html">Beta</a> (1), <a href="../../../tags/blog_setup.html">blog setup</a> (1), <a href="../../../tags/bootstrap.html">bootstrap</a> (1), <a href="../../../tags/bottleneck.html">bottleneck</a> (1), <a href="../../../tags/c.html">c++</a> (1), <a href="../../../tags/caret.html">caret</a> (1), <a href="../../../tags/cmpy.html">cmpy</a> (1), <a href="../../../tags/conditional_probability.html">conditional probability</a> (6), <a href="../../../tags/coursera.html">coursera</a> (1), <a href="../../../tags/coursera_intro_to_data_science.html">coursera intro to data science</a> (3), <a href="../../../tags/css.html">css</a> (1), <a href="../../../tags/cython.html">cython</a> (1), <a href="../../../tags/d3.html">d3</a> (1), <a href="../../../tags/dsp.html">dsp</a> (1), <a href="../../../tags/e1071.html">e1071</a> (1), <a href="../../../tags/essentia.html">essentia</a> (1), <a href="../../../tags/garmin.html">garmin</a> (1), <a href="../../../tags/ggplot2.html">ggplot2</a> (1), <a href="../../../tags/gis.html">gis</a> (1), <a href="../../../tags/git.html">git</a> (1), <a href="../../../tags/gnuplot.html">gnuplot</a> (1), <a href="../../../tags/graphs.html">graphs</a> (1), <a href="../../../tags/html5.html">html5</a> (1), <a href="../../../tags/igraph.html">igraph</a> (1), <a href="../../../tags/ipython.html">ipython</a> (1), <a href="../../../tags/javascript.html">javascript</a> (2), <a href="../../../tags/joint_probability.html">joint probability</a> (6), <a href="../../../tags/json.html">json</a> (1), <a href="../../../tags/latex.html">LaTeX</a> (1), <a href="../../../tags/lda.html">LDA</a> (1), <a href="../../../tags/lea.html">Lea</a> (2), <a href="../../../tags/machine_learning.html">machine learning</a> (1), <a href="../../../tags/marginal_probability.html">marginal probability</a> (6), <a href="../../../tags/matplotlib.html">matplotlib</a> (1), <a href="../../../tags/mir.html">mir</a> (1), <a href="../../../tags/music.html">music</a> (1), <a href="../../../tags/my_python_setup.html">my python setup</a> (5), <a href="../../../tags/my_ubuntu_setup.html">my ubuntu setup</a> (10), <a href="../../../tags/mysql.html">mysql</a> (3), <a href="../../../tags/networks.html">networks</a> (1), <a href="../../../tags/networkx.html">networkx</a> (1), <a href="../../../tags/nodejs.html">nodejs</a> (1), <a href="../../../tags/npm.html">npm</a> (1), <a href="../../../tags/numexpr.html">numexpr</a> (1), <a href="../../../tags/numpy.html">numpy</a> (1), <a href="../../../tags/octave.html">octave</a> (1), <a href="../../../tags/open_oakland.html">Open Oakland</a> (2), <a href="../../../tags/openpyxl.html">openpyxl</a> (1), <a href="../../../tags/pandas.html">pandas</a> (1), <a href="../../../tags/patsy.html">patsy</a> (1), <a href="../../../tags/pip.html">pip</a> (1), <a href="../../../tags/pweave.html">pweave</a> (1), <a href="../../../tags/pygraphviz.html">pygraphviz</a> (1), <a href="../../../tags/pymc.html">pymc</a> (1), <a href="../../../tags/pysoundfile.html">PySoundFile</a> (1), <a href="../../../tags/python.html">python</a> (10), <a href="../../../tags/python.html">Python</a> (1), <a href="../../../tags/python_2_7.html">python 2.7</a> (5), <a href="../../../tags/python_3_4.html">python 3.4</a> (1), <a href="../../../tags/pyyaml.html">pyyaml</a> (1), <a href="../../../tags/qgis.html">qgis</a> (1), <a href="../../../tags/r.html">R</a> (1), <a href="../../../tags/randomforest.html">randomForest</a> (1), <a href="../../../tags/restview.html">restview</a> (1), <a href="../../../tags/resume.html">resume</a> (1), <a href="../../../tags/rpart.html">rpart</a> (1), <a href="../../../tags/running.html">running</a> (1), <a href="../../../tags/scikit_learn.html">scikit-learn</a> (1), <a href="../../../tags/scipy.html">scipy</a> (1), <a href="../../../tags/screen.html">screen</a> (1), <a href="../../../tags/server_setup.html">server setup</a> (1), <a href="../../../tags/social_networks.html">social networks</a> (1), <a href="../../../tags/socrata.html">Socrata</a> (1), <a href="../../../tags/sound.html">sound</a> (1), <a href="../../../tags/sphinx.html">sphinx</a> (1), <a href="../../../tags/sql.html">sql</a> (4), <a href="../../../tags/sqlite3.html">sqlite3</a> (1), <a href="../../../tags/ssh.html">ssh</a> (1), <a href="../../../tags/ssh_keys.html">ssh keys</a> (1), <a href="../../../tags/statsmodels.html">statsmodels</a> (1), <a href="../../../tags/sympy.html">sympy</a> (1), <a href="../../../tags/tableau.html">tableau</a> (1), <a href="../../../tags/tinkerer.html">tinkerer</a> (1), <a href="../../../tags/topic_models.html">topic models</a> (1), <a href="../../../tags/tree.html">tree</a> (1), <a href="../../../tags/ubuntu_14_04.html">ubuntu 14.04</a> (11), <a href="../../../tags/vim.html">vim</a> (1), <a href="../../../tags/virtualbox.html">virtualbox</a> (1), <a href="../../../tags/virtualenv.html">virtualenv</a> (3), <a href="../../../tags/virtualenvwrapper.html">virtualenvwrapper</a> (2), <a href="../../../tags/vps.html">VPS</a> (1), <a href="../../../tags/yaml.html">yaml</a> (1)</div></section></aside></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><footer class="wrapper">&copy; Copyright 2014-2015 Christopher Strelioff. Powered by <a href="http://www.tinkerer.me/">Tinkerer</a> and <a href="http://sphinx.pocoo.org/">Sphinx</a>.</footer></div> <!-- footer-container -->

      </div> <!--! end of #container --><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>